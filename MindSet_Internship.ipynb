{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MindSet_Internship.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOb0bNAFo7tsFc6Ok9Di6T3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rnwgGxxsNr3"
      },
      "source": [
        "#Восстановление пропущенных значений \n",
        "По разным причинам многие наборы данных реального мира содержат пропущенные значения, часто закодированные как пробелы, NaN или другие заполнители. Однако такие наборы данных несовместимы с оценщиками scikit-learn, которые предполагают, что все значения в массиве являются числовыми, и что все они имеют и имеют значение. Основная стратегия использования неполных наборов данных — отбрасывать целые строки и / или столбцы, содержащие пропущенные значения. Однако это происходит ценой потери данных, которые могут быть ценными (хотя и неполными). Лучшая стратегия — это вменять недостающие значения, т.е. вывести их из известной части данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJJAJx7SixW7"
      },
      "source": [
        "#Импутация данных средним/медианой\n",
        "Первый спосб имутации данных - это подсчитать среднее или медиану имеющихся значений для каждого столбца в таблице и вставляем то, что получилось, в пустые ячейки. Естественно, этот метод работает только с численными данными.\n",
        "\n",
        "##Плюсы:\n",
        "Просто и быстро.\n",
        "\n",
        "Хорошо работает на небольших наборах численных данных.\n",
        "###Минусы:\n",
        "Значения вычисляются независимо для каждого столбца, так что корреляции между параметрами не учитываются.\n",
        "\n",
        "Не работает с качественными переменными.\n",
        "\n",
        "Метод не особенно точный.\n",
        "\n",
        "Никак не оценивается погрешность импутации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biBIXiZW6qtN",
        "outputId": "c37be5d2-59f3-4424-e9cc-d05d50e7a132"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import random\n",
        "import numpy as np\n",
        "random.seed(0)\n",
        "\n",
        "# Скачиваем данные:\n",
        "import pandas as pd\n",
        "dataset = fetch_california_housing()\n",
        "train, target = pd.DataFrame(dataset.data), pd.DataFrame(dataset.target)\n",
        "train.columns = ['0','1','2','3','4','5','6','7']\n",
        "train.insert(loc=len(train.columns), column='target', value=target)\n",
        "\n",
        "# Случайным образом заменяем 40% значений на NaN\n",
        "column = train['0']\n",
        "print(column.size)\n",
        "missing_pct = int(column.size * 0.4)\n",
        "i = [random.choice(range(column.shape[0])) for _ in range(missing_pct)]\n",
        "column[i] = np.NaN\n",
        "print(column.shape[0])\n",
        "\n",
        "# восстанавливаем удалённое с помощью класса SimpleImputer из scikit-learn\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer( strategy='mean') # для импутации медианой замените 'mean' на 'median'\n",
        "imp_mean.fit(train)\n",
        "imputed_train_df = imp_mean.transform(train)\n",
        "imputed_train_df"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20640\n",
            "20640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   3.87793988,   41.        ,    6.98412698, ...,   37.88      ,\n",
              "        -122.23      ,    4.526     ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,   37.86      ,\n",
              "        -122.22      ,    3.585     ],\n",
              "       [   3.87793988,   52.        ,    8.28813559, ...,   37.85      ,\n",
              "        -122.24      ,    3.521     ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,   39.43      ,\n",
              "        -121.22      ,    0.923     ],\n",
              "       [   3.87793988,   18.        ,    5.32951289, ...,   39.43      ,\n",
              "        -121.32      ,    0.847     ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,   39.37      ,\n",
              "        -121.24      ,    0.894     ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TmdrYXqjYgV"
      },
      "source": [
        "#Импутация данных самым частым значением или константой\n",
        "  Импутация самым часто встречающимся значением — ещё одна простая стратегия для компенсации пропущенных значений, не учитывающая корреляций между параметрами. Плюсы и минусы те же, что и в предыдущем пункте, но этот метод предназначен для качественных переменных.\n",
        "  В случае импутации нулём или константой (как можно догадаться из названия) все пропущенные значения в данных заменяются определённым значением."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nls3C6P1DSQ9",
        "outputId": "a54964e2-56a1-4cf3-badf-4f4893ccc57e"
      },
      "source": [
        "# Импутация классом SimpleImputer из scikit-learn\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer( strategy='most_frequent')\n",
        "imp_mean.fit(train)\n",
        "imputed_train_df = imp_mean.transform(train)\n",
        "imputed_train_df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   3.125     ,   41.        ,    6.98412698, ...,   37.88      ,\n",
              "        -122.23      ,    4.526     ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,   37.86      ,\n",
              "        -122.22      ,    3.585     ],\n",
              "       [   3.125     ,   52.        ,    8.28813559, ...,   37.85      ,\n",
              "        -122.24      ,    3.521     ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,   39.43      ,\n",
              "        -121.22      ,    0.923     ],\n",
              "       [   3.125     ,   18.        ,    5.32951289, ...,   39.43      ,\n",
              "        -121.32      ,    0.847     ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,   39.37      ,\n",
              "        -121.24      ,    0.894     ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwEhUrRtmsp0"
      },
      "source": [
        "#Импутация данных с помощью k-NN\n",
        "k-Nearest Neighbour (k ближайших соседей) — простой алгоритм классификации, который можно модифицировать для импутации недостающих значений. Он использует сходство точек, чтобы предсказать недостающие значения на основании k ближайших точек, у которых это значение есть. Иными словами, выбирается k точек, которые больше всего похожи на рассматриваемую, и уже на их основании выбирается значение для пустой ячейки. Это можно сделать с помощью библиотеки Impyute.\n",
        "Алгоритм сперва проводит импутацию простым средним, потом на основании получившегося набора данных строит дерево и использует его для поиска ближайших соседей. Взвешенное среднее их значений и вставляется в исходный набор данных вместо недостающего.\n",
        "##Плюсы:\n",
        "На некоторых датасетах может быть точнее среднего/медианы или константы.\n",
        "\n",
        "Учитывает корреляцию между параметрами.\n",
        "###Минусы:\n",
        "Вычислительно дороже, так как требует держать весь набор данных в памяти.\n",
        "\n",
        "Важно понимать, какая метрика дистанции используется для поиска соседей.\n",
        "\n",
        "Имплементация в impyute поддерживает только манхэттенскую и евклидову дистанцию, так что анализ соотношений (скажем, количества входов на сайты людей разных возрастов) может потребовать предварительной нормализации.\n",
        "\n",
        "Чувствителен к выбросам в данных (в отличие от SVM)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6_UZyRPDcfw",
        "outputId": "c94de466-9a4f-4378-ba6e-8217ed8f059e"
      },
      "source": [
        "!pip install impyute\n",
        "import sys\n",
        "from impyute.imputation.cs import fast_knn\n",
        "\n",
        "# Увеличиваем максимальную глубину рекурсии\n",
        "sys.setrecursionlimit(100000)\n",
        "\n",
        "# начинаем тренировку KNN\n",
        "imputed_training=fast_knn(train.values, k=30)\n",
        "\n",
        "imputed_training"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: impyute in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from impyute) (0.22.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.14.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (1.0.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   3.30117882,   41.        ,    6.98412698, ...,   37.88      ,\n",
              "        -122.23      ,    4.526     ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,   37.86      ,\n",
              "        -122.22      ,    3.585     ],\n",
              "       [   4.31326938,   52.        ,    8.28813559, ...,   37.85      ,\n",
              "        -122.24      ,    3.521     ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,   39.43      ,\n",
              "        -121.22      ,    0.923     ],\n",
              "       [   3.40189346,   18.        ,    5.32951289, ...,   39.43      ,\n",
              "        -121.32      ,    0.847     ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,   39.37      ,\n",
              "        -121.24      ,    0.894     ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI24E6bRoIfJ"
      },
      "source": [
        "#Импутация данных с помощью глубокого обучения\n",
        "Показано, что глубокое обучение хорошо работает с дискретными и другими не-численными значениями. Библиотека datawig позволяет восстанавливать недостающие значения за счёт тренировки нейросети на тех точках, для которых есть все параметры. Поддерживается тренировка на CPU и GPU.\n",
        "\n",
        "##Плюсы:\n",
        "Точнее других методов.\n",
        "Может работать с качественными параметрами.\n",
        "Поддерживает CPU и GPU.\n",
        "###Минусы:\n",
        "Восстанавливает только один столбец.\n",
        "\n",
        "На больших наборах данных может быть вычислительно дорого.\n",
        "\n",
        "Нужно заранее решить, какие столбцы будут использоваться для предсказания недостающего значения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxrWIcpQHLps",
        "outputId": "97f74f9a-1311-4050-ccc6-037adaf046bc"
      },
      "source": [
        "!pip install datawig\n",
        "import datawig\n",
        "\n",
        "df_train, df_test = datawig.utils.random_split(train)\n",
        "\n",
        "# Инициализируем модель SimpleImputer\n",
        "imputer = datawig.SimpleImputer(\n",
        "\tinput_columns=['1','2','3','4','5','6','7', 'target'], # из каких столбцов брать информацию для импутации\n",
        "\toutput_column= '0', # какой столбец восстанавливаем\n",
        "\toutput_path = 'imputer_model' # куда записывать модель и её метрики\n",
        "\t)\n",
        "\n",
        "# Тренируем модель\n",
        "imputer.fit(train_df=df_train, num_epochs=50)\n",
        "\n",
        "# Проводим импутацию и возвращаем восстановленный набор данных\n",
        "imputed = imputer.predict(df_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datawig in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: typing==3.6.6 in /usr/local/lib/python3.7/dist-packages (from datawig) (3.6.6)\n",
            "Requirement already satisfied: scikit-learn[alldeps]==0.22.1 in /usr/local/lib/python3.7/dist-packages (from datawig) (0.22.1)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from datawig) (0.25.3)\n",
            "Requirement already satisfied: mxnet==1.4.0 in /usr/local/lib/python3.7/dist-packages (from datawig) (1.4.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->datawig) (0.8.4)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->datawig) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->datawig) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->datawig) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->datawig) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn[alldeps]==0.22.1->datawig) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn[alldeps]==0.22.1->datawig) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3->datawig) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->datawig) (2021.5.30)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-04 20:16:25,614 [INFO]  \n",
            "========== start: fit model\n",
            "2021-08-04 20:16:25,616 [WARNING]  Already bound, ignoring bind()\n",
            "2021-08-04 20:16:26,224 [INFO]  Epoch[0] Batch [0-465]\tSpeed: 12461.31 samples/sec\tcross-entropy=9.262596\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:26,807 [INFO]  Epoch[0] Train-cross-entropy=8.884165\n",
            "2021-08-04 20:16:26,810 [INFO]  Epoch[0] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:26,812 [INFO]  Epoch[0] Time cost=1.191\n",
            "2021-08-04 20:16:26,824 [INFO]  Saved checkpoint to \"imputer_model/model-0000.params\"\n",
            "2021-08-04 20:16:26,865 [INFO]  Epoch[0] Validation-cross-entropy=7.476050\n",
            "2021-08-04 20:16:26,867 [INFO]  Epoch[0] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:27,458 [INFO]  Epoch[1] Batch [0-465]\tSpeed: 12766.86 samples/sec\tcross-entropy=13.684176\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:28,037 [INFO]  Epoch[1] Train-cross-entropy=12.796621\n",
            "2021-08-04 20:16:28,038 [INFO]  Epoch[1] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:28,044 [INFO]  Epoch[1] Time cost=1.174\n",
            "2021-08-04 20:16:28,050 [INFO]  Saved checkpoint to \"imputer_model/model-0001.params\"\n",
            "2021-08-04 20:16:28,089 [INFO]  Epoch[1] Validation-cross-entropy=7.274786\n",
            "2021-08-04 20:16:28,091 [INFO]  Epoch[1] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:28,666 [INFO]  Epoch[2] Batch [0-465]\tSpeed: 13140.43 samples/sec\tcross-entropy=8.715467\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:29,251 [INFO]  Epoch[2] Train-cross-entropy=8.844847\n",
            "2021-08-04 20:16:29,254 [INFO]  Epoch[2] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:29,257 [INFO]  Epoch[2] Time cost=1.165\n",
            "2021-08-04 20:16:29,266 [INFO]  Saved checkpoint to \"imputer_model/model-0002.params\"\n",
            "2021-08-04 20:16:29,304 [INFO]  Epoch[2] Validation-cross-entropy=7.153537\n",
            "2021-08-04 20:16:29,306 [INFO]  Epoch[2] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:29,890 [INFO]  Epoch[3] Batch [0-465]\tSpeed: 12951.88 samples/sec\tcross-entropy=7.684875\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:30,477 [INFO]  Epoch[3] Train-cross-entropy=7.977105\n",
            "2021-08-04 20:16:30,479 [INFO]  Epoch[3] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:30,482 [INFO]  Epoch[3] Time cost=1.172\n",
            "2021-08-04 20:16:30,487 [INFO]  Saved checkpoint to \"imputer_model/model-0003.params\"\n",
            "2021-08-04 20:16:30,527 [INFO]  Epoch[3] Validation-cross-entropy=7.108178\n",
            "2021-08-04 20:16:30,529 [INFO]  Epoch[3] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:31,127 [INFO]  Epoch[4] Batch [0-465]\tSpeed: 12661.39 samples/sec\tcross-entropy=8.996310\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:31,705 [INFO]  Epoch[4] Train-cross-entropy=9.032404\n",
            "2021-08-04 20:16:31,707 [INFO]  Epoch[4] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:31,709 [INFO]  Epoch[4] Time cost=1.177\n",
            "2021-08-04 20:16:31,718 [INFO]  Saved checkpoint to \"imputer_model/model-0004.params\"\n",
            "2021-08-04 20:16:31,755 [INFO]  Epoch[4] Validation-cross-entropy=7.181922\n",
            "2021-08-04 20:16:31,757 [INFO]  Epoch[4] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:32,345 [INFO]  Epoch[5] Batch [0-465]\tSpeed: 12820.34 samples/sec\tcross-entropy=8.103628\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:32,936 [INFO]  Epoch[5] Train-cross-entropy=8.779785\n",
            "2021-08-04 20:16:32,938 [INFO]  Epoch[5] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:32,940 [INFO]  Epoch[5] Time cost=1.181\n",
            "2021-08-04 20:16:32,946 [INFO]  Saved checkpoint to \"imputer_model/model-0005.params\"\n",
            "2021-08-04 20:16:32,988 [INFO]  Epoch[5] Validation-cross-entropy=7.134866\n",
            "2021-08-04 20:16:32,992 [INFO]  Epoch[5] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:33,582 [INFO]  Epoch[6] Batch [0-465]\tSpeed: 12758.68 samples/sec\tcross-entropy=9.162141\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:34,166 [INFO]  Epoch[6] Train-cross-entropy=8.786296\n",
            "2021-08-04 20:16:34,171 [INFO]  Epoch[6] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:34,174 [INFO]  Epoch[6] Time cost=1.178\n",
            "2021-08-04 20:16:34,184 [INFO]  Saved checkpoint to \"imputer_model/model-0006.params\"\n",
            "2021-08-04 20:16:34,224 [INFO]  Epoch[6] Validation-cross-entropy=7.064257\n",
            "2021-08-04 20:16:34,226 [INFO]  Epoch[6] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:34,815 [INFO]  Epoch[7] Batch [0-465]\tSpeed: 12854.87 samples/sec\tcross-entropy=7.608747\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:35,407 [INFO]  Epoch[7] Train-cross-entropy=7.444309\n",
            "2021-08-04 20:16:35,409 [INFO]  Epoch[7] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:35,411 [INFO]  Epoch[7] Time cost=1.182\n",
            "2021-08-04 20:16:35,422 [INFO]  Saved checkpoint to \"imputer_model/model-0007.params\"\n",
            "2021-08-04 20:16:35,460 [INFO]  Epoch[7] Validation-cross-entropy=6.992187\n",
            "2021-08-04 20:16:35,462 [INFO]  Epoch[7] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:36,076 [INFO]  Epoch[8] Batch [0-465]\tSpeed: 12324.78 samples/sec\tcross-entropy=7.705361\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:36,648 [INFO]  Epoch[8] Train-cross-entropy=7.578197\n",
            "2021-08-04 20:16:36,650 [INFO]  Epoch[8] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:36,653 [INFO]  Epoch[8] Time cost=1.186\n",
            "2021-08-04 20:16:36,664 [INFO]  Saved checkpoint to \"imputer_model/model-0008.params\"\n",
            "2021-08-04 20:16:36,705 [INFO]  Epoch[8] Validation-cross-entropy=6.939294\n",
            "2021-08-04 20:16:36,708 [INFO]  Epoch[8] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:37,295 [INFO]  Epoch[9] Batch [0-465]\tSpeed: 12874.60 samples/sec\tcross-entropy=7.570916\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:37,867 [INFO]  Epoch[9] Train-cross-entropy=7.410660\n",
            "2021-08-04 20:16:37,869 [INFO]  Epoch[9] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:37,871 [INFO]  Epoch[9] Time cost=1.161\n",
            "2021-08-04 20:16:37,881 [INFO]  Saved checkpoint to \"imputer_model/model-0009.params\"\n",
            "2021-08-04 20:16:37,917 [INFO]  Epoch[9] Validation-cross-entropy=6.879434\n",
            "2021-08-04 20:16:37,918 [INFO]  Epoch[9] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:38,514 [INFO]  Epoch[10] Batch [0-465]\tSpeed: 12702.53 samples/sec\tcross-entropy=8.132620\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:39,119 [INFO]  Epoch[10] Train-cross-entropy=8.025154\n",
            "2021-08-04 20:16:39,121 [INFO]  Epoch[10] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:39,124 [INFO]  Epoch[10] Time cost=1.197\n",
            "2021-08-04 20:16:39,130 [INFO]  Saved checkpoint to \"imputer_model/model-0010.params\"\n",
            "2021-08-04 20:16:39,170 [INFO]  Epoch[10] Validation-cross-entropy=7.005340\n",
            "2021-08-04 20:16:39,172 [INFO]  Epoch[10] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:39,755 [INFO]  Epoch[11] Batch [0-465]\tSpeed: 12997.74 samples/sec\tcross-entropy=7.866582\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:40,347 [INFO]  Epoch[11] Train-cross-entropy=8.027633\n",
            "2021-08-04 20:16:40,350 [INFO]  Epoch[11] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:40,360 [INFO]  Epoch[11] Time cost=1.185\n",
            "2021-08-04 20:16:40,370 [INFO]  Saved checkpoint to \"imputer_model/model-0011.params\"\n",
            "2021-08-04 20:16:40,416 [INFO]  Epoch[11] Validation-cross-entropy=7.047362\n",
            "2021-08-04 20:16:40,418 [INFO]  Epoch[11] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:41,006 [INFO]  Epoch[12] Batch [0-465]\tSpeed: 12918.77 samples/sec\tcross-entropy=7.524703\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:41,583 [INFO]  Epoch[12] Train-cross-entropy=7.360833\n",
            "2021-08-04 20:16:41,585 [INFO]  Epoch[12] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:41,591 [INFO]  Epoch[12] Time cost=1.167\n",
            "2021-08-04 20:16:41,599 [INFO]  Saved checkpoint to \"imputer_model/model-0012.params\"\n",
            "2021-08-04 20:16:41,637 [INFO]  Epoch[12] Validation-cross-entropy=6.941076\n",
            "2021-08-04 20:16:41,639 [INFO]  Epoch[12] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:42,251 [INFO]  Epoch[13] Batch [0-465]\tSpeed: 12356.87 samples/sec\tcross-entropy=7.609606\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:42,822 [INFO]  Epoch[13] Train-cross-entropy=7.455356\n",
            "2021-08-04 20:16:42,824 [INFO]  Epoch[13] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:42,827 [INFO]  Epoch[13] Time cost=1.184\n",
            "2021-08-04 20:16:42,839 [INFO]  Saved checkpoint to \"imputer_model/model-0013.params\"\n",
            "2021-08-04 20:16:42,876 [INFO]  Epoch[13] Validation-cross-entropy=6.926717\n",
            "2021-08-04 20:16:42,877 [INFO]  Epoch[13] Validation-0-accuracy=0.000000\n",
            "2021-08-04 20:16:43,460 [INFO]  Epoch[14] Batch [0-465]\tSpeed: 13011.98 samples/sec\tcross-entropy=7.583971\t0-accuracy=0.000000\n",
            "2021-08-04 20:16:44,039 [INFO]  Epoch[14] Train-cross-entropy=7.451485\n",
            "2021-08-04 20:16:44,041 [INFO]  Epoch[14] Train-0-accuracy=0.000000\n",
            "2021-08-04 20:16:44,043 [INFO]  Epoch[14] Time cost=1.164\n",
            "2021-08-04 20:16:44,052 [INFO]  Saved checkpoint to \"imputer_model/model-0014.params\"\n",
            "2021-08-04 20:16:44,089 [INFO]  No improvement detected for 5 epochs compared to 6.879434138968371 last error obtained: 6.901443090991697, stopping here\n",
            "2021-08-04 20:16:44,091 [INFO]  \n",
            "========== done (18.477436780929565 s) fit model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj7s3tRWtzwR"
      },
      "source": [
        "#Одномерное восстановление признаков\n",
        "SimpleImputer предоставляет основные стратегии для восстановления отсутствующих значений. Пропущенные значения могут быть восстановлены с использованием предоставленного постоянного значения или с использованием статистики (среднего, медианного или наиболее частого) каждого столбца, в котором находятся пропущенные значения. Этот класс также допускает различные кодировки пропущенных значений.\n",
        "\n",
        "Следующий фрагмент демонстрирует, как заменить отсутствующие значения, закодированные как np.nan, с использованием среднего значения столбцов (ось 0), содержащих отсутствующие значения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XThlJZYouKPY",
        "outputId": "314cfa10-32fd-4106-a720-bd5a90b6b3b4"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp.fit([[1, 2], [np.nan, 3], [7, 6]])\n",
        "SimpleImputer()\n",
        "X = [[np.nan, 2], [6, np.nan], [7, 6]]\n",
        "print(imp.transform(X))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.         2.        ]\n",
            " [6.         3.66666667]\n",
            " [7.         6.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAb8TtRTueW-"
      },
      "source": [
        "SimpleImputer также поддерживает разреженные матрицы (матрица с преимущественно нулевыми элементами. В противном случае, если большая часть элементов матрицы ненулевые, матрица считается плотной):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gQsKfhDu5CG",
        "outputId": "360d954c-55d8-4adf-edac-919e66d543d2"
      },
      "source": [
        "import scipy.sparse as sp\n",
        "X = sp.csc_matrix([[1, 2], [0, -1], [8, 4]])\n",
        "imp = SimpleImputer(missing_values=-1, strategy='mean')\n",
        "imp.fit(X)\n",
        "SimpleImputer(missing_values=-1)\n",
        "X_test = sp.csc_matrix([[-1, 2], [6, -1], [7, 6]])\n",
        "print(imp.transform(X_test).toarray())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3. 2.]\n",
            " [6. 3.]\n",
            " [7. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "merXWrL5vahy"
      },
      "source": [
        "Стоит обратить внимание, что этот формат не предназначен для использования для неявного хранения отсутствующих значений в матрице, поскольку он уплотняет ее во время преобразования. Отсутствующие значения, закодированные с помощью 0, должны использоваться с плотным вводом.\n",
        "\n",
        "Класс SimpleImputer также поддерживает категорические данные , представленные в виде строковых значений или панд categoricals при использовании 'most_frequent' или 'constant' стратегии:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChWEvu_ovmps",
        "outputId": "9a334ad5-cfd9-4c89-c2f9-b5690f7773ac"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([[\"a\", \"x\"],\n",
        "                   [np.nan, \"y\"],\n",
        "                   [\"a\", np.nan],\n",
        "                   [\"b\", \"y\"]],\n",
        "                  dtype=\"category\")\n",
        "\n",
        "imp = SimpleImputer(strategy=\"most_frequent\")\n",
        "print(imp.fit_transform(df))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['a' 'x']\n",
            " ['a' 'y']\n",
            " ['a' 'y']\n",
            " ['b' 'y']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}